{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('content/drive')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 環境構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fugashi==1.1.2 ipadic==1.0.0 unidic-lite\n",
    "!pip install matplotlib==3.5.2 seaborn numpy==1.22.4 openpyxl==3.0.10 tqdm XlsxWriter==3.0.3 pandas Pillow==9.0.1 plotly==5.1.0\n",
    "!pip install pytorch-lightning==1.6.4 scikit-learn scipy==1.8.1 transformers==4.19.2 tokenizers==0.12.1 sklearn==0.0 shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリのインポート，ファイルパスの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import CONFIG_NAME, WEIGHTS_NAME, BertForSequenceClassification, BertJapaneseTokenizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import StochasticWeightAveraging\n",
    "\n",
    "#MODEL_NAME = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
    "MODEL_NAME = 'cl-tohoku/bert-base-japanese-v2'\n",
    "\n",
    "TRAIN_PATH = 'path/to/train/dataset.txt'\n",
    "TEST_PATH = 'path/to/test/dataset.txt'\n",
    "FOLD = 10\n",
    "LABEL_LIST = ['A','FT','L','LF','MN','O','PE','PO','SC','SE','US','A_C']\n",
    "THRESHOLD = -1.0 #default=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModelExplainerクラス shapライブラリで分類結果を分析します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import transformers\n",
    "import numpy as np\n",
    "\n",
    "class ModelExplainer():\n",
    "    def __init__(self, model, tokenizer, labels):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.labels = labels\n",
    "    \n",
    "    def shap_explainer(self, features, answers, predicts):\n",
    "        data = np.array(features)\n",
    "        pred = transformers.pipeline(\"text-classification\",model=self.model,tokenizer=self.tokenizer,device=0,return_all_scores=True)\n",
    "        explainer = shap.Explainer(pred,output_names=list(self.labels))\n",
    "        print(\"♦SHAP可視化結果\")\n",
    "        for feature, answer, predict in zip(features, answers, predicts):\n",
    "            print(f\"予測ラベル: {predict} ,正解ラベル: {answer}\")\n",
    "            print(feature)\n",
    "            shap_values = explainer([feature])\n",
    "            shap.plots.text(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel シートの生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "#import squarify\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sb\n",
    "\n",
    "def makeClassificationResultSheet_ml(classification_result, report_result, index2label, scores_df):\n",
    "    #予測ラベルから分布図を作成\n",
    "    predicted_label = classification_result['predicted_label']\n",
    "    all_label = []\n",
    "    for labels in predicted_label:\n",
    "        lst = labels.split(',')\n",
    "        for label in lst:\n",
    "            all_label.append(label)\n",
    "\n",
    "    count = collections.Counter(all_label)\n",
    "    dist_label = []\n",
    "    for label in index2label.values():\n",
    "        if label in count:\n",
    "            dist_label.append(count[label])\n",
    "        else:\n",
    "            dist_label.append(0)\n",
    "    #グラフをメモリに一時保存\n",
    "    img = io.BytesIO()\n",
    "    fig, ax = plt.subplots() #stacked bar\n",
    "    ax.bar(index2label.values(), dist_label,label='quantity')\n",
    "    ax.legend()\n",
    "    fig.savefig(img,format='png')\n",
    "\n",
    "    #print(dist_label)\n",
    "    #分類結果をxlsxで出力\n",
    "    writer = pd.ExcelWriter('classification_result_ml.xlsx',engine='xlsxwriter')\n",
    "    classification_result.to_excel(writer,sheet_name='result',encoding='utf_8_sig',freeze_panes=[1,0])\n",
    "    #classification_reportを出力\n",
    "    report_result.to_excel(writer,sheet_name='classification_report')\n",
    "    #classification_scoresを出力\n",
    "    scores_df.to_excel(writer,sheet_name='classification_scores',freeze_panes=[1,0])\n",
    "    #エクセルシートの装飾\n",
    "    for column in classification_result:\n",
    "        column_length = max(classification_result[column].astype(str).map(len).max(),len(column))\n",
    "        col_idx = classification_result.columns.get_loc(column)\n",
    "        writer.sheets['result'].set_column(col_idx+1,col_idx+1,column_length)\n",
    "    \n",
    "    workbook = writer.book\n",
    "    color_format = workbook.add_format({'bg_color': '#9fff9c'})\n",
    "    row = len(classification_result.axes[0])+1\n",
    "    writer.sheets['result'].conditional_format('C2:C'+str(row),{\n",
    "        'type': 'formula',\n",
    "        'criteria': '=$B2=$C2',\n",
    "        'format': color_format\n",
    "    })\n",
    "    writer.sheets['result'].conditional_format('D2:D'+str(row),{\n",
    "        'type': 'formula',\n",
    "        'criteria': '=$B2=$D2',\n",
    "        'format': color_format\n",
    "    })\n",
    "    writer.sheets['result'].conditional_format('E2:E'+str(row),{\n",
    "        'type': 'formula',\n",
    "        'criteria': '=$B2=$E2',\n",
    "        'format': color_format\n",
    "    })\n",
    "    for index in range(len(scores_df.index)):\n",
    "        writer.sheets['classification_scores'].conditional_format(\n",
    "            'B'+str(index+2)+':'+'L'+str(index+2),\n",
    "            {'type': '3_color_scale',\n",
    "            'max_color': '#51f569',\n",
    "            'mid_color': 'white',\n",
    "            'min_color': '#f55151'}\n",
    "        )\n",
    "\n",
    "    writer.sheets['classification_report'].set_column(0,0,13)\n",
    "    #グラフを出力\n",
    "    writer.sheets['classification_report'].insert_image('G2','graph',{'image_data': img})\n",
    "\n",
    "    writer.save()\n",
    "\n",
    "def makeReqAnalysisSheet_ml(classification_result, index2label):\n",
    "    predicted_label = classification_result['predicted_label']\n",
    "    all_label = []\n",
    "    for labels in predicted_label:\n",
    "        lst = labels.split(',')\n",
    "        for label in lst:\n",
    "            all_label.append(label)\n",
    "\n",
    "    count = collections.Counter(all_label)\n",
    "    print(count)\n",
    "    dist_label = []\n",
    "    for label in index2label.values():\n",
    "        if label in count:\n",
    "            dist_label.append(count[label])\n",
    "        else:\n",
    "            dist_label.append(0)\n",
    "\n",
    "    #squarifyツリーマップ\n",
    "    \"\"\" treemap = io.BytesIO()\n",
    "    fig = plt.figure(figsize=(6,3))\n",
    "    plt.axis('off')\n",
    "    axis = squarify.plot(count.values(),label=count.keys(),color=sb.color_palette('Spectral',12),pad=1,text_kwargs={'fontsize': 12})\n",
    "    axis.set_title('NFR Types')\n",
    "    fig.savefig(treemap,format='png') \"\"\"\n",
    "\n",
    "    #アクセス制御のラベルを分離\n",
    "    nfr_type = []\n",
    "    is_ac = []\n",
    "    nfr_child = 0\n",
    "    fr_child = 0\n",
    "    for label in predicted_label:\n",
    "        if 'A_C' in label:\n",
    "            if label == 'A_C':\n",
    "                nfr_type.append('OTHER')\n",
    "                fr_child += 1\n",
    "            else:\n",
    "                nfr_type.append(label.replace(',A_C',''))\n",
    "                nfr_child += 1\n",
    "            is_ac.append('detected')\n",
    "        else:\n",
    "            nfr_type.append(label)\n",
    "            is_ac.append('')\n",
    "\n",
    "    #plotlyツリーマップ\n",
    "    count.pop('A_C',None)\n",
    "    label_length = len(list(count.values()))\n",
    "    labels = list(count.keys())+ ['AC','AC(NFR)']\n",
    "    parents = ['' for i in range(label_length)] + ['OTHER','SE']\n",
    "    values = list(count.values())\n",
    "    values.append(fr_child)\n",
    "    values.append(nfr_child)\n",
    "    print(values)\n",
    "    fig1 = go.Figure(go.Treemap(\n",
    "        labels= labels,\n",
    "        values= values,\n",
    "        parents= parents,\n",
    "        hovertemplate='<b>%{label} </b> <br>%{value}<br>Parent Ratio: %{percentParent:.2f}',\n",
    "        textinfo=\"label+value\",\n",
    "    ))\n",
    "    fig2 = go.Figure(go.Treemap(\n",
    "        labels= labels,\n",
    "        values= values,\n",
    "        parents= parents,\n",
    "        hovertemplate='<b>%{label} </b> <br>%{value}<br>Parent Ratio: %{percentParent:.2f}',\n",
    "        textinfo=\"label+value+percent parent+percent root\",\n",
    "        #textinfo=\"label+value,\"\n",
    "    ))\n",
    "    fig1.update_layout(\n",
    "        font=dict(\n",
    "        family=\"Times New Roman\",\n",
    "        size=20,\n",
    "        color=\"Black\"\n",
    "        ),\n",
    "        margin = dict(t=10, l=5, r=5, b=25),\n",
    "    )\n",
    "    fig2.update_layout(\n",
    "        font=dict(\n",
    "        family=\"Times New Roman\",\n",
    "        size=20,\n",
    "        color=\"Black\"\n",
    "        ),\n",
    "        margin = dict(t=50, l=25, r=25, b=25),\n",
    "    )\n",
    "    treemap2 = io.BytesIO()\n",
    "    #fig2.show()\n",
    "    fig2.write_image(treemap2,format='png', scale=1.3, engine='kaleido')\n",
    "\n",
    "    treemap = io.BytesIO()\n",
    "    fig1.write_image(treemap,format='png', scale=0.8, engine='kaleido')\n",
    "\n",
    "    #アクセス制御のラベルを分離\n",
    "    nfr_type = []\n",
    "    is_ac = []\n",
    "    for label in predicted_label:\n",
    "        if 'A_C' in label:\n",
    "            if label == 'A_C':\n",
    "                nfr_type.append('OTHER')\n",
    "            else:\n",
    "                nfr_type.append(label.replace(',A_C',''))\n",
    "            is_ac.append('detected')\n",
    "        else:\n",
    "            nfr_type.append(label)\n",
    "            is_ac.append('')\n",
    "    \n",
    "    new_df = pd.DataFrame({\n",
    "            'NFR Type': nfr_type,\n",
    "            'Acces Control': is_ac,\n",
    "            'Requirement Sentence': classification_result['text'],\n",
    "        },index=np.arange(1,len(nfr_type)+1))\n",
    "    writer = pd.ExcelWriter('requirements_analysis_ml.xlsx',engine='xlsxwriter')\n",
    "    new_df.to_excel(writer,'Analysis Result',freeze_panes=[1,0])\n",
    "    #エクセルシートの装飾\n",
    "    for column in new_df:\n",
    "        column_length = max(new_df[column].astype(str).map(len).max(),len(column))\n",
    "        col_idx = new_df.columns.get_loc(column)\n",
    "        writer.sheets['Analysis Result'].set_column(col_idx+1,col_idx+1,column_length)\n",
    "    workbook = writer.book\n",
    "    color_format = workbook.add_format({'bg_color': '#fc2163'})\n",
    "    row = len(new_df.axes[0])+1\n",
    "    writer.sheets['Analysis Result'].conditional_format('C2:C'+str(row),{\n",
    "        'type': 'formula',\n",
    "        'criteria': '$C2=\"detected\"',\n",
    "        'format': color_format\n",
    "    })\n",
    "    #ツリーマップを出力\n",
    "    placement = len(predicted_label) + 3\n",
    "    writer.sheets['Analysis Result'].insert_image(f'B{placement}','graph',{'image_data': treemap})\n",
    "\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習クラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertMultiLabelClassifier_pl(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, model_name, num_labels, lr):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.bert_mlc = BertForSequenceClassification.from_pretrained(\n",
    "            model_name, \n",
    "            num_labels=num_labels,\n",
    "            problem_type=\"multi_label_classification\",\n",
    "            attention_probs_dropout_prob=0.2,\n",
    "            hidden_dropout_prob=0.2,\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        output = self.bert_mlc(\n",
    "            input_ids=batch['input_ids'],\n",
    "            token_type_ids=batch['token_type_ids'],\n",
    "            attention_mask=batch['attention_mask'],\n",
    "            labels=batch['labels'].float()\n",
    "        )\n",
    "        loss = output.loss\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        output = self.bert_mlc(\n",
    "            input_ids=batch['input_ids'],\n",
    "            token_type_ids=batch['token_type_ids'],\n",
    "            attention_mask=batch['attention_mask'],\n",
    "            labels=batch['labels'].float()\n",
    "        )\n",
    "        val_loss = output.loss\n",
    "        scores = output.logits\n",
    "        labels_predicted = (scores > 0).int()\n",
    "        labels = batch.pop('labels')\n",
    "        num_correct = ( labels_predicted == labels ).all(-1).sum().item()\n",
    "        val_acc = num_correct/scores.size(0)\n",
    "        self.log('val_loss', val_loss)\n",
    "        self.log('val_acc', val_acc)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        labels = batch.pop('labels')\n",
    "        output = self.bert_mlc(**batch)\n",
    "        scores = output.logits\n",
    "        labels_predicted = (scores > 0).int()\n",
    "        num_correct = ( labels_predicted == labels ).all(-1).sum().item()\n",
    "        accuracy = num_correct/scores.size(0)\n",
    "        self.log('accuracy', accuracy)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.lr,weight_decay=1e-2)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの構築，予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModelHandler():\n",
    "    def __init__(self, data, label_list):\n",
    "        self.data = data\n",
    "        self.label_list = label_list\n",
    "    \n",
    "    # BERTをファインチューニングして保存する\n",
    "    def trainingTaskKFold_ml(self, generalization = False):\n",
    "        if os.path.exists('model_ml/'):\n",
    "            shutil.rmtree('model_ml/')\n",
    "    \n",
    "        if generalization:\n",
    "            num_of_training = FOLD\n",
    "        else:\n",
    "            num_of_training = 1\n",
    "    \n",
    "        dataloader_test = DataLoader(self.data['test_data'], batch_size=256)\n",
    "\n",
    "        #層化K分割で学習データと検証データに分割してファインチューニング\n",
    "        accuracy = []\n",
    "        training_data_amounts = []\n",
    "        val_data_amounts = []\n",
    "        best_model_paths = []\n",
    "        skf = StratifiedKFold(n_splits=FOLD)\n",
    "        for fold, (train_index, val_index) in enumerate(skf.split(X=self.data['dataset'],y=self.data['dataset_idx'])):\n",
    "        \n",
    "            train_data = [self.data['dataset'][i] for i in train_index]\n",
    "            val_data = [self.data['dataset'][i] for i in val_index]\n",
    "            random.shuffle(train_data)\n",
    "            training_data_amounts.append(len(train_data))\n",
    "            val_data_amounts.append(len(val_data))\n",
    "            dataloader_train = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "            dataloader_val = DataLoader(val_data, batch_size=256)\n",
    "            \n",
    "            model = BertMultiLabelClassifier_pl(\n",
    "                MODEL_NAME, num_labels=self.data['num_labels'], lr=1e-5,\n",
    "            )\n",
    "            checkpoint = pl.callbacks.ModelCheckpoint(\n",
    "                filename=f'fold={fold+1}'+'-{epoch}-{step}-{val_loss:.1f}',\n",
    "                monitor='val_loss',\n",
    "                mode='min',\n",
    "                save_top_k=1,\n",
    "                #save_last=1,\n",
    "                save_weights_only=True,\n",
    "                dirpath='model_ml/',\n",
    "            )\n",
    "            early_stop = (\n",
    "                EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    patience=3,\n",
    "                    mode='min'\n",
    "                )\n",
    "            )\n",
    "            weight_averaging = (\n",
    "                StochasticWeightAveraging(swa_lrs=1e-5)\n",
    "            )\n",
    "            # 学習方法\n",
    "            trainer = pl.Trainer(\n",
    "                gpus=1,\n",
    "                max_epochs=40,\n",
    "                log_every_n_steps=10,\n",
    "                callbacks=[checkpoint, early_stop, weight_averaging]\n",
    "            )\n",
    "            # ファインチューニング\n",
    "            trainer.fit(model,train_dataloaders=dataloader_train,val_dataloaders=dataloader_val)\n",
    "\n",
    "            print('best model: ', checkpoint.best_model_path)\n",
    "            print('val_loss: ', checkpoint.best_model_score)\n",
    "        \n",
    "            best_model_path = checkpoint.best_model_path\n",
    "\n",
    "            test = trainer.test(dataloaders=dataloader_test,ckpt_path=best_model_path)\n",
    "            print(f'Accuracy: {test[0][\"accuracy\"]:.3f}')\n",
    "            accuracy.append(test[0][\"accuracy\"])\n",
    "\n",
    "            if num_of_training == 1:\n",
    "                tmp_df = pd.DataFrame({\n",
    "                    'amount': training_data_amounts,\n",
    "                    'val_amounts': val_data_amounts\n",
    "                })\n",
    "                tmp_df.to_csv('./model_ml/training_data_amounts.csv')\n",
    "                model = BertMultiLabelClassifier_pl.load_from_checkpoint(best_model_path)\n",
    "                model.bert_mlc.save_pretrained('./model_transformers_ml/')\n",
    "                break\n",
    "            else:\n",
    "                tmp_df = pd.DataFrame({\n",
    "                    'amount': training_data_amounts,\n",
    "                    'val_amounts': val_data_amounts\n",
    "                })\n",
    "                tmp_df.to_csv('./model_ml/training_data_amounts.csv')\n",
    "                best_model_paths.append(best_model_path)\n",
    "        \n",
    "        if num_of_training != 1:\n",
    "            print(f'Average accuracy: {np.mean(accuracy):.3f}')\n",
    "            print('Starting weight averaging task ...')\n",
    "            tmp_df = pd.DataFrame({\n",
    "                'amount': training_data_amounts,\n",
    "                'val_amounts': val_data_amounts\n",
    "            })\n",
    "            tmp_df.to_csv('./model_ml/training_data_amounts.csv')\n",
    "            #print(tmp_df)\n",
    "    \n",
    "    #保存済みモデルで予測して評価する\n",
    "    def predictAndEvaluate_ml(self, mode='gpu'):\n",
    "        #保存済みモデルをロード\n",
    "        bert_mlc = BertForSequenceClassification.from_pretrained(\n",
    "            './model_transformers_ml/'\n",
    "        )\n",
    "        tokenizer = BertJapaneseTokenizer.from_pretrained(MODEL_NAME)\n",
    "        #符号化\n",
    "        encoding = tokenizer(\n",
    "            self.data['test_data_list'],\n",
    "            padding= 'longest',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        if mode == 'gpu':\n",
    "            #GPUにのせる\n",
    "            bert_mlc = bert_mlc.cuda()\n",
    "            encoding = { k: v.cuda() for k, v in encoding.items() }\n",
    "        else:\n",
    "            encoding = { k: v for k, v in encoding.items() }\n",
    "        #予測する\n",
    "        with torch.no_grad():\n",
    "            output = bert_mlc(**encoding)\n",
    "        scores = output.logits #分類スコア\n",
    "        print(scores)\n",
    "        labels_predicted = ( scores > THRESHOLD ).int().cpu().numpy().tolist() #予測ラベル(ex.[[1,0],[0,0]])\n",
    "    \n",
    "        #CPUに戻す\n",
    "        #labels_predicted = labels_predicted.cpu()\n",
    "        scores = scores.cpu()\n",
    "\n",
    "        #予測Multi-hotラベルを多クラスラベルに変換する\n",
    "        predicted = []\n",
    "        for multi_hot in labels_predicted:\n",
    "            tmp = []\n",
    "            for idx, true_or_false in enumerate(multi_hot):\n",
    "                if true_or_false == 1:\n",
    "                    tmp.append(self.data['index2label'][idx])\n",
    "            if not tmp:\n",
    "                predicted.append('OTHER')\n",
    "            else:\n",
    "                predicted.append(\",\".join(tmp))       \n",
    "    \n",
    "        #正解Multi-hotラベルを多クラスラベルに変換する\n",
    "        answer = []\n",
    "        for multi_hot in self.data['test_data_answer']:\n",
    "            tmp = []\n",
    "            for idx, true_or_false in enumerate(multi_hot):\n",
    "                if true_or_false == 1:\n",
    "                    tmp.append(self.data['index2label'][idx])\n",
    "            if not tmp:\n",
    "                answer.append('OTHER')\n",
    "            else:\n",
    "                answer.append(\",\".join(tmp))\n",
    "\n",
    "        #print('予測ラベル: ',labels_predicted)\n",
    "        #print('正解ラベル: ',self.data['test_data_answer'])\n",
    "\n",
    "        target_names = self.data['index2label'].values()\n",
    "        \n",
    "        report = classification_report(\n",
    "            self.data['test_data_answer'], labels_predicted, target_names=target_names, output_dict=True, zero_division=0\n",
    "        )\n",
    "\n",
    "        report_result = pd.DataFrame(report).T\n",
    "        display(report_result)\n",
    "\n",
    "        classification_result = pd.DataFrame({\n",
    "            'answer_label': answer,\n",
    "            'predicted_label': predicted,\n",
    "            'text': self.data['test_data_list'],\n",
    "        },index=np.arange(1,len(predicted)+1))\n",
    "\n",
    "        scores_df = pd.DataFrame(scores,columns=self.data['index2label'].values(),index=np.arange(1,len(predicted)+1))\n",
    "\n",
    "        index2label = self.data['index2label']\n",
    "        makeClassificationResultSheet_ml(classification_result,report_result,index2label,scores_df)\n",
    "        makeReqAnalysisSheet_ml(classification_result, index2label)\n",
    "        modelExplainer = ModelExplainer(model=bert_mlc,tokenizer=tokenizer,labels=target_names)\n",
    "        modelExplainer.shap_explainer(self.data['test_data_list'],self.data['test_data_answer'],predicted)\n",
    "\n",
    "def predict(features):\n",
    "    #保存済みモデルをロード\n",
    "    bert_mlc = BertForSequenceClassification.from_pretrained(\n",
    "        './model_transformers_ml/'\n",
    "    )\n",
    "    tokenizer = BertJapaneseTokenizer.from_pretrained(MODEL_NAME)\n",
    "    #符号化\n",
    "    encoding = tokenizer(\n",
    "        list(features),\n",
    "        padding= 'longest',\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    bert_mlc.cuda()\n",
    "    encoding = { k: v.cuda() for k, v in encoding.items() }\n",
    "    with torch.no_grad():\n",
    "        output = bert_mlc.forward(**encoding)\n",
    "    return output.logits.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDatasets_ml(train_path, test_path, label_list):\n",
    "    train_df = pd.read_csv(f'{train_path}', encoding='cp932')\n",
    "    test_df = pd.read_csv(f'{test_path}', encoding='cp932')\n",
    "\n",
    "    index2label = {i: k for i, k in enumerate(label_list)}\n",
    "    label2index = {k: i for i, k in enumerate(label_list)}\n",
    "    answers = [test_df[label] for label in label_list]\n",
    "    label2answers = {label: answers_array for label, answers_array in zip(label_list, answers)}\n",
    "    \n",
    "    test_data_list = test_df['feature'].tolist()\n",
    "    num_labels = len(label_list)\n",
    "\n",
    "    dataset_for_loader = []\n",
    "    test_dataset_for_loader = []\n",
    "\n",
    "    max_length = 128  # トークン数\n",
    "    tokenizer = BertJapaneseTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    dataset_idx = []\n",
    "    for idx, row in tqdm(train_df.iterrows()):\n",
    "        encoding = tokenizer(\n",
    "                row['feature'],\n",
    "                max_length=max_length,\n",
    "                padding='max_length',\n",
    "                truncation=True\n",
    "            )\n",
    "        encoding['labels'] = [row[label] for label in label_list]  # ラベルを追加\n",
    "        encoding = {k: torch.tensor(v) for k, v in encoding.items()}\n",
    "        dataset_for_loader.append(encoding)\n",
    "        dataset_idx.append(convertMultihotVector2tmpLabel(encoding['labels'].tolist()))\n",
    "    \n",
    "    test_answer = []\n",
    "    for idx, row in tqdm(test_df.iterrows()):\n",
    "        encoding = tokenizer(\n",
    "                row['feature'],\n",
    "                max_length=max_length,\n",
    "                padding='max_length',\n",
    "                truncation=True\n",
    "            )\n",
    "        encoding['labels'] = [row[label] for label in label_list]  # ラベルを追加\n",
    "        test_answer.append([row[label] for label in label_list])\n",
    "        encoding = {k: torch.tensor(v) for k, v in encoding.items()}\n",
    "        test_dataset_for_loader.append(encoding)\n",
    "\n",
    "    return {\n",
    "        'num_labels': num_labels,\n",
    "        'index2label': index2label,\n",
    "        'label2index': label2index,\n",
    "        'dataset': dataset_for_loader,\n",
    "        'dataset_idx': dataset_idx,\n",
    "        'test_data': test_dataset_for_loader,\n",
    "        'test_data_answer': test_answer,\n",
    "        'label2answers': label2answers,\n",
    "        'test_data_list': test_data_list,\n",
    "    }\n",
    "\n",
    "#one-hot形式のラベルを一時的なマルチクラスのラベルに変換する\n",
    "def convertMultihotVector2tmpLabel(mlt_hot):\n",
    "    length = len(mlt_hot)\n",
    "    label = None\n",
    "    for idx, single_one_hot_vector in enumerate(np.identity(length,dtype=int).tolist()):\n",
    "        if single_one_hot_vector == mlt_hot:\n",
    "            label = idx\n",
    "    if label == None:\n",
    "        label = length + 1 #Other\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## メインタスク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available?:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "735it [00:02, 347.20it/s] \n",
      "121it [00:00, 1632.56it/s]\n"
     ]
    }
   ],
   "source": [
    "print('Is CUDA available?: ',torch.cuda.is_available())\n",
    "\n",
    "data = loadDatasets_ml(TRAIN_PATH, TEST_PATH, LABEL_LIST)\n",
    "bmh = BertModelHandler(data, LABEL_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting training task...')\n",
    "bmh.trainingTaskKFold_ml()\n",
    "bmh.predictAndEvaluate_ml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 予測の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.8388, -2.1017, -3.5973,  ..., -1.1699, -3.7312, -2.7192],\n",
      "        [-2.5320, -2.6634, -3.5464,  ..., -0.7969, -3.6568, -1.8173],\n",
      "        [-1.9592, -2.7519, -3.1280,  ..., -2.6093, -3.5719, -3.3813],\n",
      "        ...,\n",
      "        [-2.4564, -3.0563, -3.1613,  ..., -4.1394, -0.9657, -3.0315],\n",
      "        [-3.3239, -2.7157, -1.6590,  ..., -2.8888, -2.8371, -2.9959],\n",
      "        [-1.4673, -1.3901, -3.3481,  ..., -2.6425, -3.3287, -3.4467]],\n",
      "       device='cuda:0')\n",
      "予測ラベル:  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "正解ラベル:  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MN</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PE</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PO</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SC</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_C</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.322917</td>\n",
       "      <td>0.247917</td>\n",
       "      <td>0.254099</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.281073</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>0.218035</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.095041</td>\n",
       "      <td>0.099174</td>\n",
       "      <td>0.093664</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score  support\n",
       "A              1.000000  0.500000  0.666667      6.0\n",
       "FT             0.000000  0.000000  0.000000      0.0\n",
       "L              1.000000  0.250000  0.400000      4.0\n",
       "LF             1.000000  1.000000  1.000000      2.0\n",
       "MN             0.000000  0.000000  0.000000      2.0\n",
       "O              0.000000  0.000000  0.000000      6.0\n",
       "PE             0.333333  0.500000  0.400000      2.0\n",
       "PO             0.000000  0.000000  0.000000      0.0\n",
       "SC             0.000000  0.000000  0.000000     14.0\n",
       "SE             0.166667  0.400000  0.235294     10.0\n",
       "US             0.250000  0.200000  0.222222      5.0\n",
       "A_C            0.125000  0.125000  0.125000      8.0\n",
       "micro avg      0.254902  0.220339  0.236364     59.0\n",
       "macro avg      0.322917  0.247917  0.254099     59.0\n",
       "weighted avg   0.281073  0.220339  0.218035     59.0\n",
       "samples avg    0.095041  0.099174  0.093664     59.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 1, 2, 0, 5, 3, 1, 0, 24, 4, 8]\n",
      "Counter({'OTHER': 80, 'SE': 24, 'A_C': 8, 'O': 5, 'US': 4, 'PE': 3, 'A': 3, 'LF': 2, 'PO': 1, 'L': 1})\n",
      "[80, 24, 5, 4, 2, 3, 3, 1, 1, 0, 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
      "save is not part of the public API, usage can give unexpected results and will be removed in a future version\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bmh\u001b[39m.\u001b[39;49mpredictAndEvaluate_ml()\n",
      "Cell \u001b[1;32mIn[7], line 178\u001b[0m, in \u001b[0;36mBertModelHandler.predictAndEvaluate_ml\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    176\u001b[0m index2label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[\u001b[39m'\u001b[39m\u001b[39mindex2label\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    177\u001b[0m makeClassificationResultSheet_ml(classification_result,report_result,index2label,scores_df)\n\u001b[1;32m--> 178\u001b[0m makeReqAnalysisSheet_ml(classification_result, index2label)\n\u001b[0;32m    179\u001b[0m modelExplainer \u001b[39m=\u001b[39m ModelExplainer(model\u001b[39m=\u001b[39mbert_mlc,tokenizer\u001b[39m=\u001b[39mtokenizer,labels\u001b[39m=\u001b[39mtarget_names)\n\u001b[0;32m    180\u001b[0m modelExplainer\u001b[39m.\u001b[39mshap_explainer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[\u001b[39m'\u001b[39m\u001b[39mtest_data_list\u001b[39m\u001b[39m'\u001b[39m],\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[\u001b[39m'\u001b[39m\u001b[39mtest_data_answer\u001b[39m\u001b[39m'\u001b[39m],predicted)\n",
      "Cell \u001b[1;32mIn[13], line 164\u001b[0m, in \u001b[0;36mmakeReqAnalysisSheet_ml\u001b[1;34m(classification_result, index2label)\u001b[0m\n\u001b[0;32m    155\u001b[0m fig2\u001b[39m.\u001b[39mupdate_layout(\n\u001b[0;32m    156\u001b[0m     font\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m(\n\u001b[0;32m    157\u001b[0m     family\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTimes New Roman\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m     margin \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(t\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, l\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m, r\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m, b\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m),\n\u001b[0;32m    162\u001b[0m )\n\u001b[0;32m    163\u001b[0m treemap2 \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO()\n\u001b[1;32m--> 164\u001b[0m fig2\u001b[39m.\u001b[39;49mshow()\n\u001b[0;32m    165\u001b[0m fig2\u001b[39m.\u001b[39mwrite_image(treemap2,\u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpng\u001b[39m\u001b[39m'\u001b[39m, scale\u001b[39m=\u001b[39m\u001b[39m1.3\u001b[39m, engine\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mkaleido\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    167\u001b[0m treemap \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO()\n",
      "File \u001b[1;32me:\\NLP\\bert-nfr-classification\\venv\\lib\\site-packages\\plotly\\basedatatypes.py:3398\u001b[0m, in \u001b[0;36mBaseFigure.show\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3365\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3366\u001b[0m \u001b[39mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[0;32m   3367\u001b[0m \u001b[39mspecified by the renderer argument\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3394\u001b[0m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   3395\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3396\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpio\u001b[39;00m\n\u001b[1;32m-> 3398\u001b[0m \u001b[39mreturn\u001b[39;00m pio\u001b[39m.\u001b[39mshow(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\NLP\\bert-nfr-classification\\venv\\lib\\site-packages\\plotly\\io\\_renderers.py:397\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[0;32m    392\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    393\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    394\u001b[0m         )\n\u001b[0;32m    396\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nbformat \u001b[39mor\u001b[39;00m LooseVersion(nbformat\u001b[39m.\u001b[39m__version__) \u001b[39m<\u001b[39m LooseVersion(\u001b[39m\"\u001b[39m\u001b[39m4.2.0\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 397\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         )\n\u001b[0;32m    401\u001b[0m     ipython_display\u001b[39m.\u001b[39mdisplay(bundle, raw\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    403\u001b[0m \u001b[39m# external renderers\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bmh.predictAndEvaluate_ml()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
